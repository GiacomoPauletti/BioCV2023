{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9372,"status":"ok","timestamp":1702459994377,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"xs5OEMhr6wop"},"outputs":[],"source":["import numpy as np\n","from keras import backend as keras\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","\n","from sklearn.model_selection import train_test_split\n","\n","from glob import glob\n","import cv2\n","\n","from PIL import Image\n","\n","import os\n","\n","from matplotlib import pyplot as plt\n","\n","import tensorflow.keras.backend as K"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20175,"status":"ok","timestamp":1702460026991,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"glaEMHBJ7phL","outputId":"f9b360e1-80cc-44ff-b020-0256898f57d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":570,"status":"ok","timestamp":1702460029361,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"qGo9nznl7dRP"},"outputs":[],"source":["os.chdir(\"drive/MyDrive/BioCV2023\")"]},{"cell_type":"markdown","metadata":{"id":"OsQtoKX16woy"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702460033181,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"DePjB9tV6wo2"},"outputs":[],"source":["IMAGE_SIZE = 256\n","num_classes = 5\n","batch = 4\n","LR = 1e-4\n","EPOCHS = 5\n","NUM_IMAGES = 522"]},{"cell_type":"markdown","metadata":{"id":"xeb_hiWj6wo4"},"source":["### Funzioni ausiliare\n","Qui sotto sono implementate funzioni per la creazione del dataset:\n","* caricamento percorsi\n","* divisione training/validation/test set\n","* caricamento e preprocessing immagini + maschere\n","* data augmentationc"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":930,"status":"ok","timestamp":1702463150805,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"m9jqEEWT6wo5"},"outputs":[],"source":["image_path = \"./Preprocessed_Set/T1DUAL/OutPhase/Images/\"  # da inserire\n","regex_images_paths = os.path.join(image_path, \"*.png\")\n","mask_path = \"./Preprocessed_Set/T1DUAL/OutPhase/Masks/\"   # da inserire\n","regex_masks_paths = os.path.join(mask_path, \"*.png\")\n","checkpoint_path = \"./checkpoints/checkpoint1\"\n","\n","# carica i percorsi dei dati separandoli in 80% training, 10% validation, 10% test\n","def load_data():\n","  images_paths = sorted(glob(regex_images_paths))\n","  masks_paths = sorted(glob(regex_masks_paths))\n","  train_x, tmp_x, train_y, tmp_y = train_test_split(images_paths, masks_paths, test_size=0.2, random_state=42, shuffle=True)\n","  valid_x, test_x, valid_y, test_y = train_test_split(tmp_x, tmp_y, test_size=0.5, random_state=42, shuffle=True)\n","\n","  return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1702463179903,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"tq6WVM7w6wo8"},"outputs":[],"source":["# carica l'immagine, normalizzandola a 0-1\n","def read_image(path):\n","    path = path.decode()\n","    x = np.array(Image.open(path))\n","    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE), interpolation=0)\n","    #x = x.astype(float)/255.0\n","    x = x/255.0\n","    return x\n","\n","# carica la maschera\n","def read_mask(path):\n","    path = path.decode()\n","    x = np.array(Image.open(path))\n","    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE), interpolation=0)\n","    #x = np.expand_dims(x, axis=-1) #why would I need this?\n","    return x\n","\n","# mi carica una coppia immagine-maschera\n","def tf_parse(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.uint8])\n","    x.set_shape([IMAGE_SIZE, IMAGE_SIZE])\n","    y.set_shape([IMAGE_SIZE, IMAGE_SIZE])\n","    return x, y\n","\n","def tf_dataset_train(x, y, batch=4):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))    # creo il dataset con i percorsi...\n","    dataset = dataset.shuffle(buffer_size=500)\n","    dataset = dataset.repeat()\n","    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)    # e qui \"risolvo\" i percorsi\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(1)       # per caricare in anticipo anche 1 elemento dopo\n","    return dataset\n","\n","def tf_dataset_valid(x, y, batch=batch):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.shuffle(buffer_size=50)\n","    dataset = dataset.repeat()\n","    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(1)\n","    return dataset\n"]},{"cell_type":"markdown","metadata":{"id":"M20Gcj2Q6wo-"},"source":["### Creazione modello Unet\n","Qui viene implementato il modello Unet. Da notare:\n","* non utilizzo come encoder una rete preesistente (tipicamente MobileNet) per semplicità\n","* l'output della CNN è una matrice di dimensione `(row_img, col_img, num_classes)`, dove, per ogni pixel _p_ per ogni classe _i_ assegno una probabilità (tramite softmax) al pixel di appartenere alla classe _i_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def unet(input_size = (256,256, 1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)   \n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(5, 1, activation = 'softmax')(conv9)\n","\n","    model = Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])   # posso usare metriche implementate da me (callbacks)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"zgE2Myzu6wpA"},"source":["## Creazione modello e training"]},{"cell_type":"markdown","metadata":{"id":"yD6sn6n76wpB"},"source":["### Creazione del dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":904,"status":"ok","timestamp":1702463280437,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"9kZdjADn6wpB"},"outputs":[],"source":["(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data()\n","\n","train_dataset = tf_dataset_train(train_x, train_y)\n","valid_dataset = tf_dataset_valid(valid_x, valid_y)\n","test_dataset = tf_dataset_valid(test_x, test_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1702463359583,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"LzV2CnTw6wpC","outputId":"d2a1ddec-9e60-4fdb-9d1a-ef286496233f"},"outputs":[],"source":["model = unet()\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_weights_only=False,\n","    monitor='val_accuracy',\n","    mode='auto',\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"IoaHPpNu6wpD"},"outputs":[],"source":["# Commencement of training\n","train_steps = len(train_x)//batch\n","valid_steps = len(valid_x)//batch\n","\n","if len(train_x) % batch != 0:\n","    train_steps += 1\n","if len(valid_x) % batch != 0:\n","    valid_steps += 1\n","\n","model.fit(\n","    train_dataset,\n","    validation_data = valid_dataset,\n","    epochs=EPOCHS,\n","    steps_per_epoch=train_steps,\n","    validation_steps=valid_steps,\n","    callbacks=[model_checkpoint_callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":1674,"status":"ok","timestamp":1702460750486,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"yKkQcM7T6wpD","outputId":"27da33a3-2438-41ff-a4c1-28cb83011a58"},"outputs":[],"source":["def mask_from_prob(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    return pred_mask\n","\n","def display_sample(display_list):\n","    plt.figure(figsize=(16, 16))\n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","    for i in range(len(display_list)):\n","        plt.subplot(1, len(display_list), i+1)\n","        plt.title(title[i])\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","        plt.axis('off')\n","    plt.show()\n","\n","def show_predictions():\n","    prediction = model.predict(sample_image)\n","\n","    pred_mask = mask_from_prob(prediction[0])\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(sample_image[0], cmap=\"gray\")\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(sample_mask[0], cmap=\"gray\")\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(pred_mask, cmap=\"gray\")\n","\n","for image, mask in test_dataset.take(1):\n","    sample_image, sample_mask = image, mask\n","\n","show_predictions()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5pvuHkM6wpE"},"outputs":[],"source":["model = tf.keras.models.load_model(\"./checkpoints/checkpoint0\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4481,"status":"ok","timestamp":1702456580791,"user":{"displayName":"Giacomo Pauletti","userId":"12169296531290997792"},"user_tz":-60},"id":"J-2V6MnoQ0PK","outputId":"255fbc0b-c578-46c8-dae4-78072a572f37"},"outputs":[{"name":"stdout","output_type":"stream","text":["20/20 - 4s - loss: nan - accuracy: 0.9463 - 4s/epoch - 216ms/step\n"]}],"source":["loss, acc = model.evaluate(test_dataset, verbose=2, steps=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for (x,y) in valid_dataset.take(1):\n","    imgs, msks = x,y\n","\n","for i in range(5):\n","    plt.subplot(5,3,3*i+1)\n","    plt.imshow(imgs[i], cmap=\"gray\")\n","    plt.subplot(5,3,3*i+2)\n","    plt.imshow(msks[i], cmap=\"gray\")\n","    plt.subplot(5,3,3*i+3)\n","    plt.imshow(mask_from_prob(model.predict(imgs[i])), cmap=\"gray\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
